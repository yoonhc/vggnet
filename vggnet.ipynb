{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet 구현 - 20192253 Hongchan Yoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device:  cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('current device: ',device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Load CIFAR100 Dateset & perform PCA Analysis(밑의 RGB ColourShift에 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-100 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./', train=False, download=True)\n",
    "\n",
    "# Extract RGB pixel values from the training dataset\n",
    "pixels = np.vstack([np.asarray(img).reshape(-1, 3) for img, _ in train_dataset])\n",
    "\n",
    "# Compute the covariance matrix of the RGB pixel values\n",
    "cov_matrix = np.cov(pixels, rowvar=False)\n",
    "\n",
    "# Perform eigen decomposition to obtain eigenvectors and eigenvalues\n",
    "eig_vals, eig_vecs = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "# Ensure eigenvalues and eigenvectors are sorted in descending order\n",
    "sorted_indices = np.argsort(eig_vals)[::-1]\n",
    "eig_vals = eig_vals[sorted_indices]\n",
    "eig_vecs = eig_vecs[:, sorted_indices]\n",
    "\n",
    "print(\"Eigenvalues:\", eig_vals)\n",
    "print(\"Eigenvectors:\\n\", eig_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Define Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2numpy(image):\n",
    "    if torch.is_tensor(image):\n",
    "        image = image.data.cpu().numpy()\n",
    "    else:\n",
    "        image = np.array(image)\n",
    "    return image\n",
    "\n",
    "'''\n",
    "VGGNet Paper - To further augment the training set, the crops underwent random horizontal flipping and random RGB colour shift\n",
    "\n",
    "다만 Dataset을 논문과 같이 ILSVRC-2014를 사용하지 않고, 이미지 크기가 32x32인 CIFAR100 을 사용할 것이기에 논문과 같이 Training Scale S에 맞춰 Resize후\n",
    "Crop 하는 방식은 사용하지 않고, 32x32 image 부분에 5x5 crop(구멍)을 내준다.\n",
    "'''\n",
    "class RandomCrop(object):\n",
    "    def __init__(self, crop_pixel:int = 5):\n",
    "        self.crop_pixel = crop_pixel\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = convert2numpy(image)\n",
    "        # Image: Height x Width x Channel\n",
    "        x_y = np.random.choice(image.shape[0] - self.crop_pixel, 2)\n",
    "        start_x, start_y = x_y[0], x_y[1]\n",
    "        image[start_x: start_x + self.crop_pixel, start_y: start_y + self.crop_pixel, :] = 0.0\n",
    "\n",
    "        return image\n",
    "\n",
    "# Random Horizontal Flipping\n",
    "# probability의 확률로 flipping 실행\n",
    "class RandomHorizontalFlip(object):\n",
    "    def __init__(self, probability = 0.3):\n",
    "        assert probability >= 0.0 and probability <= 1.0\n",
    "        self.probability = probability\n",
    "\n",
    "    def __call__(self, image):\n",
    "        self.execute = np.random.rand() < self.probability\n",
    "        if self.execute:\n",
    "            new_image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            return new_image\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "# Random RGB Colour Shift\n",
    "# probability의 확률로 Colour Shift 실행\n",
    "# VGGNet 논문에서는 RGB Colour Shift에 대한 자세한 내용은 없고, AlexNet 논문만 인용.\n",
    "# 따라서 AlexNet의 RGB Colour Shif(PCA 연산 후 더하기)로 구현\n",
    "'''AlexNet - To each training image, we add multiples of the found principal components\n",
    "with magnitudes proportional to the corresponding eigenvalues times a random variable drawn from\n",
    "a Gaussian with mean zero and standard deviation 0.1'''\n",
    "class RandomRGBColourShift(object):\n",
    "    def __init__(self, eig_vecs, eig_vals, alpha_std=0.1):\n",
    "        \"\"\"\n",
    "        Initialize with precomputed eigenvectors and eigenvalues.\n",
    "        \n",
    "        Parameters:\n",
    "        - eig_vecs: eigenvectors of the covariance matrix of RGB pixel values\n",
    "        - eig_vals: eigenvalues of the covariance matrix of RGB pixel values\n",
    "        - alpha_std: standard deviation of the Gaussian from which alphas are drawn\n",
    "        - probability: probability of applying the color shift\n",
    "        \"\"\"\n",
    "        self.eig_vecs = eig_vecs\n",
    "        self.eig_vals = eig_vals\n",
    "        self.alpha_std = alpha_std\n",
    "\n",
    "    def __call__(self, image):\n",
    "        alpha = np.random.normal(0, self.alpha_std, 3)\n",
    "        quantity = np.dot(self.eig_vecs, alpha * self.eig_vals)\n",
    "        new_image = image.astype(np.float32)\n",
    "        for i in range(3):  # For R, G, B channels\n",
    "            new_image[:, :, i] += quantity[i]\n",
    "        new_image = np.clip(new_image, 0, 255).astype(np.uint8)\n",
    "        return new_image\n",
    "\n",
    "def imshow(img):\n",
    "    # Un-normalize and display the image\n",
    "    img = img / 2 + 0.5\n",
    "    plt.imshow(np.transpose(img, (1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply augmentation to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    RandomCrop(),\n",
    "    RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize(32),\n",
    "    #torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                    (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize(32),\n",
    "    # torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                     (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100(root='./', train=True, download=True, transform=train_transform),\n",
    "    batch_size=128, shuffle=True, num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100(root='./', train=False, download=True, transform=test_transform),\n",
    "    batch_size=128, shuffle=False, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the augmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "# Convert images to numpy for display\n",
    "images = images.numpy()\n",
    "\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "           \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# Plot the images in the batch\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "# Display 20 images\n",
    "# Viaulize Images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
